#!/usr/bin/env bash

function mysql_init() {
  _generate_db_cnf || return 1
}

function mysql_export_db() {
  local path_to_dumpfile="$1"

  eval $(get_config_as "user" "environments.dev.database.user")
  eval $(get_config_as "pass" "environments.dev.database.pass")
  eval $(get_config_as "name" "environments.dev.database.name")
  local save_as="$EXPORT_DB_PATH/$name.$(date8601 -c).sql"
  local defaults_file=$(_get_path_to_credentials)
  [ ! -f "$defaults_file" ] && ! _generate_db_cnf && return 1

  # First make sure the file does not exist.
  if [ -f "$save_as" ]; then
    rm "$save_as" || fail_because "$save_as exists and cannot be deleted"
    return 1
  fi

  # @link https://zoomadmin.com/HowToLinux/LinuxCommand/mysqldump
  eval $(get_config_as -a 'settings' 'environments.dev.export.mysqldump_options')

  local shared_options
  if [[ null != ${settings[@]} ]]; then
    for option in ${settings[@]}; do
      shared_options=" $shared_options --$option"
    done
  fi

  # Dump create table structure
  local structure_tables=$(_get_dump_structure_table_list)
  if [[ "$structure_tables" ]]; then
    local options="$shared_options --add-drop-table --no-data "
    mysqldump --defaults-file="$defaults_file"$options "$name" $structure_tables >> "$save_as"
  fi

  # Dump table data
  local data_tables=$(_get_dump_data_table_list)
  if [[ "$data_tables" ]]; then
    local options="$shared_options --skip-add-drop-table --no-create-info"
    mysqldump --defaults-file="$defaults_file"$options "$name" $data_tables >> "$save_as"
  fi

  succeed_because "Saved to $save_as"
}

function mysql_import_db() {
  local path_to_dumpfile="$1"

  if [[ ! "$path_to_dumpfile" ]]; then
    fail_because "No import filename given." && return 1
  fi

  if [ -f "$path_to_dumpfile" ]; then
    fail_because "Import file \"$path_to_dumpfile\" does not exist." && return 1
  fi


  throw "$path_to_dumpfile;$0;in function ${FUNCNAME}();$LINENO"

}

##
# Generate the local.cnf with db creds.
#
function _generate_db_cnf() {
  eval $(get_config_as "host" "environments.dev.database.host")
  eval $(get_config_as "port" "environments.dev.database.port")
  eval $(get_config_as "name" "environments.dev.database.name")
  eval $(get_config_as "user" "environments.dev.database.user")
  eval $(get_config_as "pass" "environments.dev.database.pass")

  # Handle the mysql protocol.
  eval $(get_config_as "protocol" "environments.dev.database.protocol")
  if [[ ! "$protocol" ]]; then
    protocol='tcp'
    if [[ "$host" == 'localhost' ]] || [[ "$host" == '127.0.0.1' ]]; then
      protocol='socket'
    fi
  fi

  local path_to_cnf=$(_get_path_to_credentials)
  if ! touch "$path_to_cnf" || ! chmod 0600 "$path_to_cnf"; then
    fail_because "Could not create $path_to_cnf"
    return 1
  fi

  # Create the .cnf file
  echo "# AUTOGENERATED, DO NOT EDIT!" >"$path_to_cnf"
  echo "[client]" >>"$path_to_cnf"
  echo "host=\"$host\"" >>"$path_to_cnf"
  [ "$port" ] && echo "port=\"$port\"" >>"$path_to_cnf"
  echo "user=\"$user\"" >>"$path_to_cnf"
  echo "password=\"$pass\"" >>"$path_to_cnf"
  echo "protocol=\"$protocol\"" >>"$path_to_cnf"
  chmod 400 "$path_to_cnf"
  succeed_because "Replaced file at $path_to_cnf"
}

function _get_path_to_credentials() {
  echo "$CONFIG_DIR/credentials--$LOCAL_ENV.local.cnf"
}

# These are the tables whose structure only should be dumped.
#
function _get_dump_structure_table_list() {
  local table_query="SET group_concat_max_len = 10240;"
  table_query="${table_query} SELECT GROUP_CONCAT(table_name separator ' ')"

  eval $(get_config_as "name" "environments.dev.database.name")
  table_query="${table_query} FROM information_schema.tables WHERE table_schema='$name'"

  # Omit the tables listed in tables.ignore.
  eval $(get_config_as "ignore_tables" "environments.dev.export.exclude_tables_listed_in")
  local path="$EXPORT_DB_PATH/$ignore_tables"
  table_query="${table_query}$(_build_where_not_query $path)"

  mysql --defaults-file="$defaults_file" -AN -e"$table_query"
}

# These are the tables whose content only should be dumped
#
function _get_dump_data_table_list() {
  eval $(get_config_as "name" "environments.dev.database.name")
  local table_query="SET group_concat_max_len = 10240;"
  table_query="${table_query} SELECT GROUP_CONCAT(table_name separator ' ')"
  table_query="${table_query} FROM information_schema.tables WHERE table_schema='$name'"

  # Omit the tables listed in data.ignore.
  eval $(get_config_as "ignore_data" "environments.dev.export.exclude_data_from_tables_listed_in")
  local path="$EXPORT_DB_PATH/$ignore_data"
  table_query="${table_query}$(_build_where_not_query $path)"

  # Omit the tables listed in tables.ignore.
  eval $(get_config_as "ignore_tables" "environments.dev.export.exclude_tables_listed_in")
  local path="$EXPORT_DB_PATH/$ignore_tables"
  table_query="${table_query}$(_build_where_not_query $path)"

  mysql --defaults-file="$defaults_file" -AN -e"$table_query"
}

# Build a tablename query expanding wildcards from a file of tablenames
#
# $1 - string - Filepath to the list of tablenames.
#
function _build_where_not_query() {
  local path_to_table_list="$1"

  # Nothing to do if there is no file
  [ -f "$path_to_table_list" ] || return 0

  local csv
  local where
  while read p; do
    if [[ $p == *"%"* ]]; then
      where="$where AND table_name NOT LIKE '$p'"
    else
      csv="$csv,'$p'"
    fi
  done <"$path_to_table_list"

  csv=${csv#,}
  if [[ "$csv" ]]; then
    where="$where AND table_name NOT IN ($csv)"
  fi
  echo "$where"
}

function mysql_reset_db() {
  local dumpfile=$(get_path_to_fetched_db)
  mysql_import_db "$dumpfile"
}


#function mysql_reset_db() {
#  (cd "$PULL_DB_PATH" && lando db-import "$(get_path_to_fetched_db)")
#}

function mysql_reset_files() {
#  rsync -av "$PULL_FILES_PATH/" "$ROOT_DIR/)"
}
